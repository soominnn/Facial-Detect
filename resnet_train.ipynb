{"cells":[{"cell_type":"code","execution_count":null,"id":"7160ae02","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:45:49.126722Z","iopub.status.busy":"2022-05-28T11:45:49.124613Z","iopub.status.idle":"2022-05-28T11:45:55.728983Z","shell.execute_reply":"2022-05-28T11:45:55.728205Z"},"id":"7160ae02","papermill":{"duration":6.617721,"end_time":"2022-05-28T11:45:55.731210","exception":false,"start_time":"2022-05-28T11:45:49.113489","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","import shutil\n","import random\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential, load_model\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, BatchNormalization, Dropout, Reshape, Input\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.optimizers.schedules import CosineDecay\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback, LearningRateScheduler\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras import layers\n","from tensorflow.keras.mixed_precision import experimental as mixed_precision\n","import matplotlib.pyplot as plt\n","import itertools\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"id":"d29cd0fa","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:45:55.744103Z","iopub.status.busy":"2022-05-28T11:45:55.743629Z","iopub.status.idle":"2022-05-28T11:45:58.195070Z","shell.execute_reply":"2022-05-28T11:45:58.193822Z"},"id":"d29cd0fa","outputId":"37c37639-0013-4088-b572-c08a5619867f","papermill":{"duration":2.461617,"end_time":"2022-05-28T11:45:58.198866","exception":false,"start_time":"2022-05-28T11:45:55.737249","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"]},{"name":"stderr","output_type":"stream","text":["2022-05-28 11:45:55.809663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:55.967925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:55.968671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:55.976452: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-05-28 11:45:55.976769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:55.977519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:55.978172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:58.181034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:58.182019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:58.182717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-05-28 11:45:58.183346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"]}],"source":["# gpu 준비\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)"]},{"cell_type":"code","execution_count":null,"id":"b7a8fd47","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:45:58.214399Z","iopub.status.busy":"2022-05-28T11:45:58.214059Z","iopub.status.idle":"2022-05-28T11:46:04.729164Z","shell.execute_reply":"2022-05-28T11:46:04.728213Z"},"id":"b7a8fd47","outputId":"30d424ac-c6b6-48b1-9f2b-c3ead6199844","papermill":{"duration":6.524695,"end_time":"2022-05-28T11:46:04.731128","exception":false,"start_time":"2022-05-28T11:45:58.206433","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhhan14\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.12.17 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.12.16"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20220528_114600-o5enucwg</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/hhan14/resnet-fer-keras-0/runs/o5enucwg\" target=\"_blank\">astral-resonance-4</a></strong> to <a href=\"https://wandb.ai/hhan14/resnet-fer-keras-0\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hhan14/resnet-fer-keras-0/runs/o5enucwg?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7fb17c1c2610>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","from wandb.keras import WandbCallback\n","\n","wandb.login(key=wandb_api_key)\n","wandb.init(project=\"resnet-fer-keras-0\")"]},{"cell_type":"code","execution_count":null,"id":"b818ab4f","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:04.749401Z","iopub.status.busy":"2022-05-28T11:46:04.749082Z","iopub.status.idle":"2022-05-28T11:46:10.467340Z","shell.execute_reply":"2022-05-28T11:46:10.466374Z"},"id":"b818ab4f","outputId":"1e1449ed-1e84-49bf-f42d-f74077b254aa","papermill":{"duration":5.729269,"end_time":"2022-05-28T11:46:10.469544","exception":false,"start_time":"2022-05-28T11:46:04.740275","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["fer2013/fer2013.csv\r\n","fer2013/README\r\n","fer2013/fer2013.bib\r\n","fer2013/\r\n"]}],"source":["!tar xzvf ../input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013.tar.gz\n","%mkdir ./models"]},{"cell_type":"code","execution_count":null,"id":"49c67fc6","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:10.484856Z","iopub.status.busy":"2022-05-28T11:46:10.484554Z","iopub.status.idle":"2022-05-28T11:46:10.489387Z","shell.execute_reply":"2022-05-28T11:46:10.488623Z"},"id":"49c67fc6","papermill":{"duration":0.014375,"end_time":"2022-05-28T11:46:10.491068","exception":false,"start_time":"2022-05-28T11:46:10.476693","status":"completed"},"tags":[]},"outputs":[],"source":["DATA_PATH = \"./fer2013/fer2013.csv\""]},{"cell_type":"code","execution_count":null,"id":"0d74ae5a","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:10.512842Z","iopub.status.busy":"2022-05-28T11:46:10.512511Z","iopub.status.idle":"2022-05-28T11:46:11.225913Z","shell.execute_reply":"2022-05-28T11:46:11.224987Z"},"id":"0d74ae5a","outputId":"87b71bcb-8bd6-4e86-9296-40b33af91c77","papermill":{"duration":0.728892,"end_time":"2022-05-28T11:46:11.228035","exception":false,"start_time":"2022-05-28T11:46:10.499143","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-7ed3589b-eafb-b891-ce82-e4610321b848)\r\n"]}],"source":["!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"id":"06411d1f","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:11.243797Z","iopub.status.busy":"2022-05-28T11:46:11.243057Z","iopub.status.idle":"2022-05-28T11:46:11.276412Z","shell.execute_reply":"2022-05-28T11:46:11.275182Z"},"id":"06411d1f","outputId":"640303ea-3b1a-4822-e76c-127997f67d48","papermill":{"duration":0.042742,"end_time":"2022-05-28T11:46:11.278090","exception":false,"start_time":"2022-05-28T11:46:11.235348","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-05-28 11:46:11.245911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"]}],"source":["policy = mixed_precision.Policy('mixed_float16')\n","mixed_precision.set_policy(policy)"]},{"cell_type":"code","execution_count":null,"id":"fc3cd522","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:11.292986Z","iopub.status.busy":"2022-05-28T11:46:11.292314Z","iopub.status.idle":"2022-05-28T11:46:11.306598Z","shell.execute_reply":"2022-05-28T11:46:11.305916Z"},"id":"fc3cd522","papermill":{"duration":0.023432,"end_time":"2022-05-28T11:46:11.308269","exception":false,"start_time":"2022-05-28T11:46:11.284837","status":"completed"},"tags":[]},"outputs":[],"source":["# 참조: https://minimin2.tistory.com/100\n","# 매 epoch 마다 data augmentation을 진행하기 위한 dataloader class\n","\n","class Dataloader(Sequence):\n","    def __init__(self, x_set, y_set, transform=None, batch_size=64, shuffle=True):\n","        self.x, self.y = x_set, y_set\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.transform = transform # data augmentation 진행할 torchvision transform 모듈\n","        self.on_epoch_end()\n","    \n","    def img_preprocess(self, idx):\n","        img = np.array(self.x[idx])\n","        img = Image.fromarray(img)\n","        if self.transform:\n","            img = self.transform(img)\n","        label = np.array([self.y[idx]] * 10)\n","        return img, label\n","\n","    def __len__(self):\n","        return math.ceil(len(self.x) / self.batch_size)\n","\n","    # 데이터를 batch size 만큼 불러오며 img_preprocess 통해 augmentation 한 데이터 반환\n","    def __getitem__(self, idx):\n","        indices = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n","\n","        batch_x_list, batch_y_list = map(list, zip(*[self.img_preprocess(i) for i in indices]))\n","        \n","        batch_x = np.array(batch_x_list)\n","        batch_y = np.array(batch_y_list)\n","        \n","        bs, ncrops, h, w, c = batch_x.shape\n","        batch_x = batch_x.reshape([-1, h, w, c])\n","        \n","        bs, ncrops, labels = batch_y.shape\n","        batch_y = batch_y.reshape([-1, labels])\n","\n","        return batch_x, batch_y\n","\n","    def on_epoch_end(self):\n","        self.indices = np.arange(len(self.x))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indices)"]},{"cell_type":"code","execution_count":null,"id":"19e2dc23","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:11.323031Z","iopub.status.busy":"2022-05-28T11:46:11.322713Z","iopub.status.idle":"2022-05-28T11:46:13.153054Z","shell.execute_reply":"2022-05-28T11:46:13.152147Z"},"id":"19e2dc23","papermill":{"duration":1.841373,"end_time":"2022-05-28T11:46:13.156213","exception":false,"start_time":"2022-05-28T11:46:11.314840","status":"completed"},"tags":[]},"outputs":[],"source":["# 참조: https://github.com/usef-kh/fer/blob/master/data/fer2013.py\n","def load_data(path=DATA_PATH):\n","    fer2013 = pd.read_csv(path)\n","    emotion_mapping = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n","\n","    return fer2013, emotion_mapping\n","\n","# df에서 이미지와 label을 추출하여 array로 반환\n","def prepare_data(data):\n","    image_array = np.zeros(shape=(len(data), 48, 48))\n","    image_label = np.array(list(map(int, data['emotion'])))\n","    \n","    onehot_encoder = OneHotEncoder()\n","    image_label = image_label.reshape(-1, 1)\n","    image_label = onehot_encoder.fit_transform(image_label)\n","    image_label = image_label.toarray()\n","\n","    for i, row in enumerate(data.index):\n","        image = np.fromstring(data.loc[row, 'pixels'], dtype=int, sep=' ')\n","        image = np.reshape(image, (48, 48))\n","        image_array[i] = image\n","\n","    return image_array, image_label\n","\n","\n","def get_dataloaders(path=DATA_PATH, bs=64, augment=True):\n","    fer2013, emotion_mapping = load_data(path)\n","\n","    xtrain, ytrain = prepare_data(fer2013[fer2013['Usage'] == 'Training'])\n","    xval, yval = prepare_data(fer2013[fer2013['Usage'] == 'PrivateTest'])\n","    xtest, ytest = prepare_data(fer2013[fer2013['Usage'] == 'PublicTest'])\n","\n","    mu, st = 0, 255\n","\n","    test_transform = transforms.Compose([\n","        transforms.TenCrop(40),\n","        transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n","        transforms.Lambda(lambda tensors: torch.stack([transforms.Normalize(mean=(mu,), std=(st,))(t) for t in tensors]).permute(0, 2, 3, 1).numpy()),\n","    ])\n","\n","    if augment:\n","        train_transform = transforms.Compose([\n","            transforms.RandomResizedCrop(48, scale=(0.8, 1.2)), # randomly rescale\n","            transforms.RandomApply([transforms.RandomAffine(0, translate=(0.2, 0.2))], p=0.5), # randomly translate\n","            transforms.RandomHorizontalFlip(),# randomly horizontal flip\n","            transforms.RandomApply([transforms.RandomRotation(10)], p=0.5), # randomly rotate\n","            transforms.TenCrop(40), # ten-crop\n","            transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n","            transforms.Lambda(lambda tensors: torch.stack([transforms.Normalize(mean=(mu,), std=(st,))(t) for t in tensors])), # normalize\n","            transforms.Lambda(lambda tensors: torch.stack([transforms.RandomErasing(p=0.5)(t) for t in tensors]).permute(0, 2, 3, 1).numpy()), # keras 모델의 입력인 (batch size, 40, 40, 1) input에 맞도록 reshape\n","        ])\n","    else:\n","        train_transform = test_transform\n","\n","    trainloader = Dataloader(xtrain, ytrain, transform=train_transform, batch_size=128)\n","    valloader = Dataloader(xval, yval, transform=test_transform, batch_size=128)\n","    testloader = Dataloader(xtest, ytest, transform=test_transform, shuffle=False, batch_size=128)\n","\n","    return trainloader, valloader, testloader\n","\n","# 후에 정확도 측정 및 confusion matrix 생성을 위해 test 데이터 label만 불러오는 메서드\n","def get_test_labels():\n","    fer2013, emotion_mapping = load_data(DATA_PATH)\n","    x_test, y_test = prepare_data(fer2013[fer2013['Usage'] == 'PublicTest'])\n","    \n","    mu, st = 0, 255\n","\n","    test_transform = transforms.Compose([\n","        transforms.TenCrop(40),\n","        transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n","        transforms.Lambda(lambda tensors: torch.stack([transforms.Normalize(mean=(mu,), std=(st,))(t) for t in tensors]).permute(0, 2, 3, 1).numpy()),\n","    ])\n","\n","    testloader_cm = Dataloader(x_test, y_test, batch_size=3589, transform=test_transform, shuffle=False)\n","    xtest, ytest = next(iter(testloader_cm))\n","    \n","    return emotion_mapping, np.argmax(ytest, axis=1) "]},{"cell_type":"code","execution_count":null,"id":"eaa12cb6","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:13.187082Z","iopub.status.busy":"2022-05-28T11:46:13.186742Z","iopub.status.idle":"2022-05-28T11:46:19.601963Z","shell.execute_reply":"2022-05-28T11:46:19.601073Z"},"id":"eaa12cb6","papermill":{"duration":6.428736,"end_time":"2022-05-28T11:46:19.604039","exception":false,"start_time":"2022-05-28T11:46:13.175303","status":"completed"},"tags":[]},"outputs":[],"source":["trainloader, valloader, testloader = get_dataloaders(bs=128)"]},{"cell_type":"code","execution_count":null,"id":"6f0db008","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:19.619893Z","iopub.status.busy":"2022-05-28T11:46:19.619515Z","iopub.status.idle":"2022-05-28T11:46:19.628157Z","shell.execute_reply":"2022-05-28T11:46:19.627212Z"},"id":"6f0db008","papermill":{"duration":0.018638,"end_time":"2022-05-28T11:46:19.629994","exception":false,"start_time":"2022-05-28T11:46:19.611356","status":"completed"},"tags":[]},"outputs":[],"source":["# 참조: https://towardsdatascience.com/learning-rate-schedules-and-adaptive-learning-rate-methods-for-deep-learning-2c8f433990d1\n","\n","class AccHistory(Callback):\n","    def on_train_begin(self, logs={}):\n","        self.acc = []\n","        self.lr = []\n","        \n","    def on_epoch_end(self, batch, logs={}):\n","        self.acc.append(logs.get('accuracy'))\n","        self.lr.append(step_decay(len(self.acc)))\n","        print('lr:', step_decay(len(self.acc)))\n","\n","def step_decay(epoch):\n","    initial_lrate = 0.1\n","    drop = 0.5\n","    epochs_drop = 10.0\n","    lrate = initial_lrate * math.pow(drop, math.floor((epoch)/epochs_drop))\n","    return lrate\n","\n","acc_history = AccHistory()\n","lrate = LearningRateScheduler(step_decay)"]},{"cell_type":"code","execution_count":null,"id":"413f0847","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:19.645340Z","iopub.status.busy":"2022-05-28T11:46:19.644960Z","iopub.status.idle":"2022-05-28T11:46:19.656598Z","shell.execute_reply":"2022-05-28T11:46:19.655625Z"},"id":"413f0847","papermill":{"duration":0.021682,"end_time":"2022-05-28T11:46:19.658687","exception":false,"start_time":"2022-05-28T11:46:19.637005","status":"completed"},"tags":[]},"outputs":[],"source":["#참고 논문 : Deep Residual Learning for Image Recognition (https://arxiv.org/abs/1512.03385)\n","#코드 : 핸즈온 머신러닝 2판(책) 14장 5절\n","#Resnet34는 34개 층으로 이루어져있고, 64개의 특성 맵을 출력하는 3개의 Residual Unit, 128개의 특성 맵을 출력하는 4개의 Residual Unit, 512개의 특성 맵을 출력하는 3개의 Residual Unit을 포함한다\n","#먼저 Residual Unit층을 구현한다.\n","class Residual_Unit(keras.layers.Layer):\n","    def __init__(self, filters, strides = 1, activation = 'relu',**kwargs):\n","        super().__init__(**kwargs)\n","        self.activation = keras.activations.get(activation)\n","        self.main_layers = [\n","            keras.layers.Conv2D(filters,3,strides = strides,padding = \"same\",use_bias = False),\n","            keras.layers.BatchNormalization(),\n","            self.activation,\n","            keras.layers.Conv2D(filters,3,strides = 1,padding = \"same\",use_bias = False),\n","            keras.layers.BatchNormalization()\n","        ]\n","        #main_layers는 convolution과 batch normalization을 사용하는 기본적인 구조다.\n","        self.skip_layers = []\n","        if strides > 1 :\n","            self.skip_layers = [\n","                keras.layers.Conv2D(filters,1,strides = strides,padding = \"same\",use_bias = False),\n","                keras.layers.BatchNormalization()\n","            ]\n","        #skip_layers는 convolution과 batch normalization을 stride가 1보다 큰 경우에만 적용한다. 즉, 입력과 출력의 크기가 다른 경우를 의미한다. \n","        #입력과 출력의 크기가 다르면 입력이 Residual Unit의 출력에 바로 더해질 수 없다.\n","\n","    def get_config(self):\n","      config = super().get_config().copy()\n","      config.update({\n","          'activation' : self.activation,\n","          'main_layers' : self.main_layers,\n","          'skip_layers' : self.skip_layers,\n","      })\n","      return config\n","            \n","    def call(self,inputs):\n","       x = inputs\n","       for layer in self.main_layers :\n","         x = layer(x)\n","         skip = inputs\n","       for layer in self.skip_layers:\n","         skip = layer(skip)\n","       return self.activation(x+skip)\n","    #call()은 input을 main layer와 skip layer에 통과시키고 두 출력을 더하여 activation function에 통과시킨다."]},{"cell_type":"code","execution_count":null,"id":"8c26132d","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:19.678127Z","iopub.status.busy":"2022-05-28T11:46:19.677707Z","iopub.status.idle":"2022-05-28T11:46:22.987719Z","shell.execute_reply":"2022-05-28T11:46:22.986753Z"},"id":"8c26132d","papermill":{"duration":3.323783,"end_time":"2022-05-28T11:46:22.989839","exception":false,"start_time":"2022-05-28T11:46:19.666056","status":"completed"},"tags":[]},"outputs":[],"source":["model = keras.models.Sequential()\n","#Residual Unit을 준비해두었기 때문에 Residual Unit을 하나의 층처럼 취급할 수 있다. 그러므로 Sequential class를 이용해 구현한다.\n","input_shape = (40, 40, 1)\n","model.add(keras.layers.Input(shape=input_shape))\n","\n","prev_filters = 32\n","for filters in [32]*3 + [64]*4 + [128]*6 + [256]*3 : \n","    strides = 1 if filters == prev_filters else 2\n","    model.add(Residual_Unit(filters,strides = strides))\n","    prev_filters = filters\n","#64개의 특성 맵을 출력하는 3개의 Residual Unit, 128개의 특성 맵을 출력하는 4개의 Residual Unit, 512개의 특성 맵을 출력하는 3개의 Residual Unit을 for문을 이용해 구현해주었다.\n","#Filter 개수가 이전과 같으면 stride를 1, 아니면 2로 설정하고, filter개수를 계속 update해주었다.\n","model.add(keras.layers.GlobalAvgPool2D())\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dropout(0.2))\n","model.add(keras.layers.Dense(7,activation = \"softmax\"))\n","#참고 논문 : Deep Residual Learning for Image Recognition (https://arxiv.org/abs/1512.03385)\n","#코드 : 핸즈온 머신러닝 2판(책) 14장 5절"]},{"cell_type":"code","execution_count":null,"id":"d5a38b35","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:23.005434Z","iopub.status.busy":"2022-05-28T11:46:23.004767Z","iopub.status.idle":"2022-05-28T11:46:23.024955Z","shell.execute_reply":"2022-05-28T11:46:23.024282Z"},"id":"d5a38b35","papermill":{"duration":0.02991,"end_time":"2022-05-28T11:46:23.026678","exception":false,"start_time":"2022-05-28T11:46:22.996768","status":"completed"},"tags":[]},"outputs":[],"source":["opt = SGD(learning_rate=0.01, momentum=0.9, nesterov=True, decay=0.0001) # Stochastic Gradient Descent(확률적 경사 하강법) 이용\n","# val loss를 모니터 하여 정체될 경우 lr 감소\n","lr_schedule = ReduceLROnPlateau(\n","    monitor=\"val_loss\",\n","    factor=0.75,\n","    patience=5,\n","    verbose=True\n",")\n","\n","model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"id":"4ce72921","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:23.041372Z","iopub.status.busy":"2022-05-28T11:46:23.040725Z","iopub.status.idle":"2022-05-28T11:46:23.057493Z","shell.execute_reply":"2022-05-28T11:46:23.055498Z"},"id":"4ce72921","outputId":"1fb6fe47-70ac-415e-8d6e-787e7dea661f","papermill":{"duration":0.026317,"end_time":"2022-05-28T11:46:23.059707","exception":false,"start_time":"2022-05-28T11:46:23.033390","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","res__unit (Res_Unit)         (None, 40, 40, 32)        9760      \n","_________________________________________________________________\n","res__unit_1 (Res_Unit)       (None, 40, 40, 32)        18688     \n","_________________________________________________________________\n","res__unit_2 (Res_Unit)       (None, 40, 40, 32)        18688     \n","_________________________________________________________________\n","res__unit_3 (Res_Unit)       (None, 20, 20, 64)        58112     \n","_________________________________________________________________\n","res__unit_4 (Res_Unit)       (None, 20, 20, 64)        74240     \n","_________________________________________________________________\n","res__unit_5 (Res_Unit)       (None, 20, 20, 64)        74240     \n","_________________________________________________________________\n","res__unit_6 (Res_Unit)       (None, 20, 20, 64)        74240     \n","_________________________________________________________________\n","res__unit_7 (Res_Unit)       (None, 10, 10, 128)       230912    \n","_________________________________________________________________\n","res__unit_8 (Res_Unit)       (None, 10, 10, 128)       295936    \n","_________________________________________________________________\n","res__unit_9 (Res_Unit)       (None, 10, 10, 128)       295936    \n","_________________________________________________________________\n","res__unit_10 (Res_Unit)      (None, 10, 10, 128)       295936    \n","_________________________________________________________________\n","res__unit_11 (Res_Unit)      (None, 10, 10, 128)       295936    \n","_________________________________________________________________\n","res__unit_12 (Res_Unit)      (None, 10, 10, 128)       295936    \n","_________________________________________________________________\n","res__unit_13 (Res_Unit)      (None, 5, 5, 256)         920576    \n","_________________________________________________________________\n","res__unit_14 (Res_Unit)      (None, 5, 5, 256)         1181696   \n","_________________________________________________________________\n","res__unit_15 (Res_Unit)      (None, 5, 5, 256)         1181696   \n","_________________________________________________________________\n","global_average_pooling2d (Gl (None, 256)               0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 256)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 7)                 1799      \n","=================================================================\n","Total params: 5,324,327\n","Trainable params: 5,315,879\n","Non-trainable params: 8,448\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"id":"4e991532","metadata":{"execution":{"iopub.execute_input":"2022-05-28T11:46:23.074862Z","iopub.status.busy":"2022-05-28T11:46:23.074614Z","iopub.status.idle":"2022-05-28T16:31:03.040012Z","shell.execute_reply":"2022-05-28T16:31:03.039257Z"},"id":"4e991532","outputId":"273fbccf-0d0d-4b06-9a59-226ddc676237","papermill":{"duration":17081.4372,"end_time":"2022-05-28T16:31:04.504334","exception":false,"start_time":"2022-05-28T11:46:23.067134","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n","2022-05-28 11:46:23.786929: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n"]},{"name":"stderr","output_type":"stream","text":["2022-05-28 11:46:29.378344: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"]},{"name":"stdout","output_type":"stream","text":["225/225 [==============================] - 185s 766ms/step - loss: 1.8821 - accuracy: 0.2402 - val_loss: 1.9066 - val_accuracy: 0.2436\n","lr: 0.1\n","Epoch 2/150\n","225/225 [==============================] - 169s 747ms/step - loss: 1.6409 - accuracy: 0.3454 - val_loss: 1.5250 - val_accuracy: 0.4009\n","lr: 0.1\n","Epoch 3/150\n","225/225 [==============================] - 168s 745ms/step - loss: 1.4908 - accuracy: 0.4182 - val_loss: 1.6333 - val_accuracy: 0.3721\n","lr: 0.1\n","Epoch 4/150\n","225/225 [==============================] - 168s 744ms/step - loss: 1.3896 - accuracy: 0.4649 - val_loss: 1.3493 - val_accuracy: 0.4851\n","lr: 0.1\n","Epoch 5/150\n","225/225 [==============================] - 168s 746ms/step - loss: 1.3162 - accuracy: 0.4952 - val_loss: 1.2093 - val_accuracy: 0.5412\n","lr: 0.1\n","Epoch 6/150\n","225/225 [==============================] - 169s 748ms/step - loss: 1.2601 - accuracy: 0.5195 - val_loss: 1.2455 - val_accuracy: 0.5372\n","lr: 0.1\n","Epoch 7/150\n","225/225 [==============================] - 169s 747ms/step - loss: 1.2137 - accuracy: 0.5400 - val_loss: 1.3259 - val_accuracy: 0.5303\n","lr: 0.1\n","Epoch 8/150\n","225/225 [==============================] - 168s 744ms/step - loss: 1.1822 - accuracy: 0.5514 - val_loss: 1.5176 - val_accuracy: 0.5155\n","lr: 0.1\n","Epoch 9/150\n","225/225 [==============================] - 168s 745ms/step - loss: 1.1568 - accuracy: 0.5625 - val_loss: 1.3231 - val_accuracy: 0.5393\n","lr: 0.1\n","Epoch 10/150\n","225/225 [==============================] - 168s 747ms/step - loss: 1.1307 - accuracy: 0.5712 - val_loss: 1.1238 - val_accuracy: 0.5873\n","lr: 0.05\n","Epoch 11/150\n","225/225 [==============================] - 169s 751ms/step - loss: 1.1046 - accuracy: 0.5822 - val_loss: 1.1635 - val_accuracy: 0.5894\n","lr: 0.05\n","Epoch 12/150\n","225/225 [==============================] - 168s 745ms/step - loss: 1.0871 - accuracy: 0.5878 - val_loss: 1.1459 - val_accuracy: 0.5795\n","lr: 0.05\n","Epoch 13/150\n","225/225 [==============================] - 167s 743ms/step - loss: 1.0704 - accuracy: 0.5951 - val_loss: 1.1248 - val_accuracy: 0.5819\n","lr: 0.05\n","Epoch 14/150\n","225/225 [==============================] - 168s 746ms/step - loss: 1.0504 - accuracy: 0.6045 - val_loss: 0.9815 - val_accuracy: 0.6351\n","lr: 0.05\n","Epoch 15/150\n","225/225 [==============================] - 170s 753ms/step - loss: 1.0359 - accuracy: 0.6098 - val_loss: 1.1110 - val_accuracy: 0.5746\n","lr: 0.05\n","Epoch 16/150\n","225/225 [==============================] - 168s 746ms/step - loss: 1.0216 - accuracy: 0.6135 - val_loss: 1.0539 - val_accuracy: 0.6089\n","lr: 0.05\n","Epoch 17/150\n","225/225 [==============================] - 168s 744ms/step - loss: 1.0059 - accuracy: 0.6201 - val_loss: 1.1607 - val_accuracy: 0.5722\n","lr: 0.05\n","Epoch 18/150\n","225/225 [==============================] - 168s 744ms/step - loss: 0.9977 - accuracy: 0.6227 - val_loss: 1.1555 - val_accuracy: 0.5728\n","lr: 0.05\n","Epoch 19/150\n","225/225 [==============================] - 169s 750ms/step - loss: 0.9849 - accuracy: 0.6276 - val_loss: 1.0399 - val_accuracy: 0.6266\n","lr: 0.05\n","\n","Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n","Epoch 20/150\n","225/225 [==============================] - 169s 748ms/step - loss: 0.9537 - accuracy: 0.6408 - val_loss: 1.0251 - val_accuracy: 0.6308\n","lr: 0.025\n","Epoch 21/150\n","225/225 [==============================] - 168s 747ms/step - loss: 0.9444 - accuracy: 0.6437 - val_loss: 1.0303 - val_accuracy: 0.6308\n","lr: 0.025\n","Epoch 22/150\n","225/225 [==============================] - 170s 755ms/step - loss: 0.9361 - accuracy: 0.6468 - val_loss: 1.0067 - val_accuracy: 0.6388\n","lr: 0.025\n","Epoch 23/150\n","225/225 [==============================] - 171s 758ms/step - loss: 0.9241 - accuracy: 0.6520 - val_loss: 1.1437 - val_accuracy: 0.6203\n","lr: 0.025\n","Epoch 24/150\n","225/225 [==============================] - 168s 746ms/step - loss: 0.9126 - accuracy: 0.6576 - val_loss: 1.0168 - val_accuracy: 0.6313\n","lr: 0.025\n","\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n","Epoch 25/150\n","225/225 [==============================] - 169s 746ms/step - loss: 0.8963 - accuracy: 0.6639 - val_loss: 1.4052 - val_accuracy: 0.5708\n","lr: 0.025\n","Epoch 26/150\n","225/225 [==============================] - 169s 748ms/step - loss: 0.8828 - accuracy: 0.6674 - val_loss: 1.2677 - val_accuracy: 0.6016\n","lr: 0.025\n","Epoch 27/150\n","225/225 [==============================] - 170s 753ms/step - loss: 0.8752 - accuracy: 0.6709 - val_loss: 0.9739 - val_accuracy: 0.6515\n","lr: 0.025\n","Epoch 28/150\n","225/225 [==============================] - 169s 751ms/step - loss: 0.8704 - accuracy: 0.6724 - val_loss: 1.0240 - val_accuracy: 0.6488\n","lr: 0.025\n","Epoch 29/150\n","225/225 [==============================] - 169s 749ms/step - loss: 0.8622 - accuracy: 0.6758 - val_loss: 1.1503 - val_accuracy: 0.6048\n","lr: 0.025\n","Epoch 30/150\n","225/225 [==============================] - 169s 750ms/step - loss: 0.8542 - accuracy: 0.6796 - val_loss: 0.9866 - val_accuracy: 0.6523\n","lr: 0.0125\n","Epoch 31/150\n","225/225 [==============================] - 169s 751ms/step - loss: 0.8476 - accuracy: 0.6808 - val_loss: 0.9878 - val_accuracy: 0.6504\n","lr: 0.0125\n","Epoch 32/150\n","225/225 [==============================] - 169s 748ms/step - loss: 0.8426 - accuracy: 0.6814 - val_loss: 1.0594 - val_accuracy: 0.6273\n","lr: 0.0125\n","\n","Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n","Epoch 33/150\n","225/225 [==============================] - 169s 748ms/step - loss: 0.8195 - accuracy: 0.6915 - val_loss: 0.9293 - val_accuracy: 0.6641\n","lr: 0.0125\n","Epoch 34/150\n","225/225 [==============================] - 171s 759ms/step - loss: 0.8169 - accuracy: 0.6928 - val_loss: 0.9304 - val_accuracy: 0.6704\n","lr: 0.0125\n","Epoch 35/150\n","225/225 [==============================] - 169s 750ms/step - loss: 0.8105 - accuracy: 0.6959 - val_loss: 0.9418 - val_accuracy: 0.6663\n","lr: 0.0125\n","Epoch 36/150\n","225/225 [==============================] - 169s 749ms/step - loss: 0.8021 - accuracy: 0.6987 - val_loss: 0.9537 - val_accuracy: 0.6639\n","lr: 0.0125\n","Epoch 37/150\n","225/225 [==============================] - 170s 755ms/step - loss: 0.7972 - accuracy: 0.7003 - val_loss: 0.9483 - val_accuracy: 0.6621\n","lr: 0.0125\n","Epoch 38/150\n","225/225 [==============================] - 170s 753ms/step - loss: 0.7926 - accuracy: 0.7024 - val_loss: 1.0402 - val_accuracy: 0.6344\n","lr: 0.0125\n","\n","Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.003164062276482582.\n","Epoch 39/150\n","225/225 [==============================] - 170s 752ms/step - loss: 0.7769 - accuracy: 0.7089 - val_loss: 0.9802 - val_accuracy: 0.6581\n","lr: 0.0125\n","Epoch 40/150\n","225/225 [==============================] - 170s 752ms/step - loss: 0.7738 - accuracy: 0.7095 - val_loss: 1.0328 - val_accuracy: 0.6453\n","lr: 0.00625\n","Epoch 41/150\n","225/225 [==============================] - 170s 755ms/step - loss: 0.7646 - accuracy: 0.7117 - val_loss: 0.9610 - val_accuracy: 0.6747\n","lr: 0.00625\n","Epoch 42/150\n","225/225 [==============================] - 171s 758ms/step - loss: 0.7643 - accuracy: 0.7141 - val_loss: 0.9658 - val_accuracy: 0.6664\n","lr: 0.00625\n","Epoch 43/150\n","225/225 [==============================] - 169s 751ms/step - loss: 0.7584 - accuracy: 0.7154 - val_loss: 0.9946 - val_accuracy: 0.6471\n","lr: 0.00625\n","\n","Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0023730467073619366.\n","Epoch 44/150\n","225/225 [==============================] - 169s 751ms/step - loss: 0.7429 - accuracy: 0.7209 - val_loss: 0.9693 - val_accuracy: 0.6677\n","lr: 0.00625\n","Epoch 45/150\n","225/225 [==============================] - 170s 755ms/step - loss: 0.7417 - accuracy: 0.7213 - val_loss: 0.9590 - val_accuracy: 0.6694\n","lr: 0.00625\n","Epoch 46/150\n","225/225 [==============================] - 171s 756ms/step - loss: 0.7376 - accuracy: 0.7236 - val_loss: 1.0324 - val_accuracy: 0.6525\n","lr: 0.00625\n","Epoch 47/150\n","225/225 [==============================] - 169s 750ms/step - loss: 0.7321 - accuracy: 0.7255 - val_loss: 0.9549 - val_accuracy: 0.6706\n","lr: 0.00625\n","Epoch 48/150\n","225/225 [==============================] - 170s 755ms/step - loss: 0.7267 - accuracy: 0.7279 - val_loss: 0.9867 - val_accuracy: 0.6707\n","lr: 0.00625\n","\n","Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0017797850305214524.\n","Epoch 49/150\n","225/225 [==============================] - 170s 754ms/step - loss: 0.7160 - accuracy: 0.7331 - val_loss: 0.9642 - val_accuracy: 0.6792\n","lr: 0.00625\n","Epoch 50/150\n","225/225 [==============================] - 171s 759ms/step - loss: 0.7153 - accuracy: 0.7319 - val_loss: 0.9472 - val_accuracy: 0.6785\n","lr: 0.003125\n","Epoch 51/150\n","225/225 [==============================] - 172s 760ms/step - loss: 0.7101 - accuracy: 0.7348 - val_loss: 0.9868 - val_accuracy: 0.6685\n","lr: 0.003125\n","Epoch 52/150\n","225/225 [==============================] - 170s 753ms/step - loss: 0.7101 - accuracy: 0.7332 - val_loss: 0.9855 - val_accuracy: 0.6736\n","lr: 0.003125\n","Epoch 53/150\n","225/225 [==============================] - 171s 757ms/step - loss: 0.7051 - accuracy: 0.7363 - val_loss: 0.9423 - val_accuracy: 0.6811\n","lr: 0.003125\n","\n","Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0013348387728910893.\n","Epoch 54/150\n","225/225 [==============================] - 172s 762ms/step - loss: 0.6924 - accuracy: 0.7404 - val_loss: 0.9647 - val_accuracy: 0.6739\n","lr: 0.003125\n","Epoch 55/150\n","225/225 [==============================] - 170s 754ms/step - loss: 0.6987 - accuracy: 0.7390 - val_loss: 0.9674 - val_accuracy: 0.6739\n","lr: 0.003125\n","Epoch 56/150\n","225/225 [==============================] - 171s 756ms/step - loss: 0.6956 - accuracy: 0.7397 - val_loss: 0.9909 - val_accuracy: 0.6699\n","lr: 0.003125\n","Epoch 57/150\n","225/225 [==============================] - 172s 760ms/step - loss: 0.6882 - accuracy: 0.7436 - val_loss: 0.9709 - val_accuracy: 0.6811\n","lr: 0.003125\n","Epoch 58/150\n","225/225 [==============================] - 171s 759ms/step - loss: 0.6861 - accuracy: 0.7436 - val_loss: 0.9847 - val_accuracy: 0.6769\n","lr: 0.003125\n","\n","Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0010011291014961898.\n","Epoch 59/150\n","225/225 [==============================] - 170s 753ms/step - loss: 0.6790 - accuracy: 0.7449 - val_loss: 0.9539 - val_accuracy: 0.6770\n","lr: 0.003125\n","Epoch 60/150\n","225/225 [==============================] - 171s 757ms/step - loss: 0.6795 - accuracy: 0.7451 - val_loss: 0.9751 - val_accuracy: 0.6768\n","lr: 0.0015625\n","Epoch 61/150\n","225/225 [==============================] - 171s 757ms/step - loss: 0.6816 - accuracy: 0.7445 - val_loss: 0.9584 - val_accuracy: 0.6816\n","lr: 0.0015625\n","Epoch 62/150\n","225/225 [==============================] - 172s 761ms/step - loss: 0.6783 - accuracy: 0.7457 - val_loss: 0.9743 - val_accuracy: 0.6790\n","lr: 0.0015625\n","Epoch 63/150\n","225/225 [==============================] - 171s 760ms/step - loss: 0.6761 - accuracy: 0.7474 - val_loss: 0.9717 - val_accuracy: 0.6800\n","lr: 0.0015625\n","\n","Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0007508468697778881.\n","Epoch 64/150\n","225/225 [==============================] - 171s 758ms/step - loss: 0.6706 - accuracy: 0.7483 - val_loss: 0.9824 - val_accuracy: 0.6800\n","lr: 0.0015625\n","Epoch 65/150\n","225/225 [==============================] - 170s 755ms/step - loss: 0.6674 - accuracy: 0.7509 - val_loss: 0.9782 - val_accuracy: 0.6790\n","lr: 0.0015625\n","Epoch 66/150\n","225/225 [==============================] - 173s 768ms/step - loss: 0.6701 - accuracy: 0.7492 - val_loss: 0.9608 - val_accuracy: 0.6813\n","lr: 0.0015625\n","Epoch 67/150\n","225/225 [==============================] - 172s 762ms/step - loss: 0.6620 - accuracy: 0.7519 - val_loss: 0.9762 - val_accuracy: 0.6814\n","lr: 0.0015625\n","Epoch 68/150\n","225/225 [==============================] - 175s 777ms/step - loss: 0.6641 - accuracy: 0.7512 - val_loss: 0.9654 - val_accuracy: 0.6829\n","lr: 0.0015625\n","\n","Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.000563135152333416.\n","Epoch 69/150\n","225/225 [==============================] - 172s 762ms/step - loss: 0.6600 - accuracy: 0.7537 - val_loss: 0.9776 - val_accuracy: 0.6823\n","lr: 0.0015625\n","Epoch 70/150\n","225/225 [==============================] - 172s 762ms/step - loss: 0.6609 - accuracy: 0.7538 - val_loss: 0.9731 - val_accuracy: 0.6833\n","lr: 0.00078125\n","Epoch 71/150\n","225/225 [==============================] - 172s 761ms/step - loss: 0.6547 - accuracy: 0.7551 - val_loss: 0.9818 - val_accuracy: 0.6819\n","lr: 0.00078125\n","Epoch 72/150\n","225/225 [==============================] - 172s 762ms/step - loss: 0.6595 - accuracy: 0.7532 - val_loss: 0.9811 - val_accuracy: 0.6831\n","lr: 0.00078125\n","Epoch 73/150\n","225/225 [==============================] - 172s 761ms/step - loss: 0.6600 - accuracy: 0.7537 - val_loss: 0.9855 - val_accuracy: 0.6818\n","lr: 0.00078125\n","\n","Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0004223513533361256.\n","Epoch 74/150\n","225/225 [==============================] - 172s 761ms/step - loss: 0.6555 - accuracy: 0.7548 - val_loss: 0.9706 - val_accuracy: 0.6847\n","lr: 0.00078125\n","Epoch 75/150\n","225/225 [==============================] - 170s 756ms/step - loss: 0.6512 - accuracy: 0.7565 - val_loss: 0.9742 - val_accuracy: 0.6860\n","lr: 0.00078125\n","Epoch 76/150\n","225/225 [==============================] - 171s 758ms/step - loss: 0.6515 - accuracy: 0.7577 - val_loss: 0.9706 - val_accuracy: 0.6846\n","lr: 0.00078125\n","Epoch 77/150\n","225/225 [==============================] - 171s 757ms/step - loss: 0.6575 - accuracy: 0.7551 - val_loss: 0.9821 - val_accuracy: 0.6837\n","lr: 0.00078125\n","Epoch 78/150\n","225/225 [==============================] - 171s 759ms/step - loss: 0.6537 - accuracy: 0.7561 - val_loss: 0.9748 - val_accuracy: 0.6820\n","lr: 0.00078125\n","\n","Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0003167635150020942.\n","Epoch 79/150\n","225/225 [==============================] - 172s 760ms/step - loss: 0.6482 - accuracy: 0.7580 - val_loss: 0.9703 - val_accuracy: 0.6839\n","lr: 0.00078125\n","Epoch 80/150\n","225/225 [==============================] - 171s 757ms/step - loss: 0.6480 - accuracy: 0.7581 - val_loss: 0.9799 - val_accuracy: 0.6831\n","lr: 0.000390625\n","Epoch 81/150\n","225/225 [==============================] - 172s 762ms/step - loss: 0.6493 - accuracy: 0.7573 - val_loss: 0.9822 - val_accuracy: 0.6857\n","lr: 0.000390625\n","Epoch 82/150\n","225/225 [==============================] - 173s 765ms/step - loss: 0.6478 - accuracy: 0.7587 - val_loss: 0.9853 - val_accuracy: 0.6841\n","lr: 0.000390625\n","Epoch 83/150\n","225/225 [==============================] - 171s 755ms/step - loss: 0.6504 - accuracy: 0.7576 - val_loss: 0.9828 - val_accuracy: 0.6834\n","lr: 0.000390625\n","\n","Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00023757264716550708.\n","Epoch 84/150\n","225/225 [==============================] - 170s 754ms/step - loss: 0.6461 - accuracy: 0.7575 - val_loss: 0.9723 - val_accuracy: 0.6861\n","lr: 0.000390625\n","Epoch 85/150\n","225/225 [==============================] - 171s 758ms/step - loss: 0.6477 - accuracy: 0.7583 - val_loss: 0.9729 - val_accuracy: 0.6874\n","lr: 0.000390625\n","Epoch 86/150\n","225/225 [==============================] - 171s 758ms/step - loss: 0.6463 - accuracy: 0.7585 - val_loss: 0.9775 - val_accuracy: 0.6853\n","lr: 0.000390625\n","Epoch 87/150\n","225/225 [==============================] - 172s 764ms/step - loss: 0.6479 - accuracy: 0.7581 - val_loss: 0.9742 - val_accuracy: 0.6851\n","lr: 0.000390625\n","Epoch 88/150\n","225/225 [==============================] - 173s 764ms/step - loss: 0.6453 - accuracy: 0.7591 - val_loss: 0.9794 - val_accuracy: 0.6846\n","lr: 0.000390625\n","\n","Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.0001781794853741303.\n","Epoch 89/150\n","225/225 [==============================] - 172s 760ms/step - loss: 0.6406 - accuracy: 0.7603 - val_loss: 0.9820 - val_accuracy: 0.6858\n","lr: 0.000390625\n","Epoch 90/150\n","225/225 [==============================] - 174s 769ms/step - loss: 0.6396 - accuracy: 0.7616 - val_loss: 0.9765 - val_accuracy: 0.6861\n","lr: 0.0001953125\n","Epoch 91/150\n","225/225 [==============================] - 172s 762ms/step - loss: 0.6416 - accuracy: 0.7603 - val_loss: 0.9671 - val_accuracy: 0.6871\n","lr: 0.0001953125\n","Epoch 92/150\n","225/225 [==============================] - 172s 760ms/step - loss: 0.6417 - accuracy: 0.7611 - val_loss: 0.9782 - val_accuracy: 0.6869\n","lr: 0.0001953125\n","Epoch 93/150\n","225/225 [==============================] - 172s 761ms/step - loss: 0.6412 - accuracy: 0.7612 - val_loss: 0.9796 - val_accuracy: 0.6857\n","lr: 0.0001953125\n","\n","Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00013363461403059773.\n","Epoch 94/150\n","225/225 [==============================] - 172s 760ms/step - loss: 0.6436 - accuracy: 0.7588 - val_loss: 0.9750 - val_accuracy: 0.6859\n","lr: 0.0001953125\n","Epoch 95/150\n","225/225 [==============================] - 172s 763ms/step - loss: 0.6397 - accuracy: 0.7608 - val_loss: 0.9759 - val_accuracy: 0.6874\n","lr: 0.0001953125\n","Epoch 00095: early stopping\n"]}],"source":["acc_model_path = 'models/best_acc_model.h5'\n","\n","acc_checkpoint = ModelCheckpoint(filepath=acc_model_path, monitor='val_accuracy', save_best_only=True, save_weights_only=False, save_freq=\"epoch\")\n","early = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, mode='auto')\n","\n","wandb.config = {\n","  \"epochs\": 150,\n","  \"batch_size\": 128\n","}\n","\n","hist = model.fit(\n","    trainloader,\n","    validation_data=valloader,\n","    epochs=150,\n","    batch_size=128,\n","    callbacks=[acc_checkpoint, early, acc_history, lr_schedule, WandbCallback()],\n",")\n","\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"id":"6316c97d","metadata":{"execution":{"iopub.execute_input":"2022-05-28T16:31:07.593229Z","iopub.status.busy":"2022-05-28T16:31:07.592585Z","iopub.status.idle":"2022-05-28T16:31:17.243089Z","shell.execute_reply":"2022-05-28T16:31:17.242330Z"},"id":"6316c97d","papermill":{"duration":11.314585,"end_time":"2022-05-28T16:31:17.245406","exception":false,"start_time":"2022-05-28T16:31:05.930821","status":"completed"},"tags":[],"outputId":"23cc1f25-3e86-4f50-ed3e-9137a5fd62c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["29/29 [==============================] - 9s 314ms/step - loss: 1.0371 - accuracy: 0.6714\n","[1.0370680093765259, 0.6714405417442322]\n"]}],"source":["hist = model.evaluate(testloader)\n","print(hist)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":17176.132351,"end_time":"2022-05-28T16:31:57.105097","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-05-28T11:45:40.972746","version":"2.3.4"},"colab":{"name":"resnet_train.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}